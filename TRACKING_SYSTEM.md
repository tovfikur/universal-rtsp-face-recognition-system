# ğŸ¯ Person-Face Tracking System Documentation

## Overview

The enhanced face & person recognition system now includes **persistent tracking** with unique IDs that link detected persons with their recognized faces. This provides continuous "who-and-where" tracking across frames.

---

## ğŸš€ Key Features

### 1. **Persistent Tracking IDs**
- Each person detected gets a unique ID (e.g., `person_1`, `person_2`)
- IDs persist across frames even when face is temporarily not visible
- Uses IoU-based matching to maintain identity continuity

### 2. **Person-Face Linking**
- Automatically links detected faces to their corresponding person bounding box
- Validates face is inside person region before linking
- Maintains face recognition data even when face temporarily disappears

### 3. **Color-Coded Bounding Boxes**

| Color  | Status | Description |
|--------|--------|-------------|
| ğŸŸ© **Green** | Known | Face recognized and matched to database |
| ğŸŸ¨ **Yellow** | Tracking | Person detected, face not yet identified |
| ğŸŸ¥ **Red** | Unknown | Face detected but not in database |

### 4. **Intelligent Status Management**
- **Tracking**: Initial state when person first detected
- **Known**: After face matched to database
- **Unknown**: After face detected but not recognized
- Status persists with ID until face re-identification

---

## ğŸ§  System Architecture

### Backend Components

#### **1. SimpleTracker (`tracker.py`)**
Main tracking engine implementing ByteTrack-style algorithm:

```python
person_tracker = SimpleTracker(
    iou_threshold=0.3,      # Min IoU for matching
    max_age=30,             # Max frames to keep lost tracks
    min_hits=1,             # Min detections before confirmed
    face_memory_time=3.0    # Remember face for 3 seconds
)
```

**Key Methods:**
- `update(detections)` - Update tracker with new person detections
- `update_face_recognition(track_id, face_bbox, name, confidence)` - Link face data to track
- `get_all_tracks()` - Get all active tracked persons

#### **2. TrackedPerson Data Structure**
```python
@dataclass
class TrackedPerson:
    track_id: int                    # Unique persistent ID
    person_bbox: List[float]         # [x1, y1, x2, y2]
    confidence: float                # Person detection confidence

    # Face recognition
    face_bbox: Optional[List[float]] # Face location
    name: str                        # Recognized name or "â€”"
    face_confidence: float           # Face match confidence
    status: str                      # "Known", "Unknown", "Tracking"

    # Tracking metadata
    last_seen: float                 # Timestamp
    frames_tracked: int              # Total frames
    frames_lost: int                 # Consecutive lost frames
    face_last_seen: float           # Last face detection time
```

#### **3. Detection Pipeline**

```
Frame Input
    â†“
[1] YOLO Person Detection
    â†“
[2] Update Tracker (assign/update IDs)
    â†“
[3] For each tracked person:
    - Extract person region
    - Detect faces in region
    - Match faces to database
    - Link face to person ID
    â†“
[4] Return tracked persons with status
    â†“
Frontend Display
```

### Frontend Components

#### **Bounding Box Rendering**
Each tracked person displays:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â† Color-coded border
â”‚ ID: person_3            â”‚
â”‚ Name: Tovfikur Rahman   â”‚  â† Green if Known
â”‚ Conf: 92%               â”‚  â† Face confidence
â”‚ Status: Known           â”‚  â† Color-coded status
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    [Person Box]
        â†“
    [Face Box] â† Dashed line indicator
```

---

## ğŸ“Š Tracking Behavior

### Scenario 1: New Person Enters
```
Frame 1: Person detected â†’ Assign ID: person_1
         Status: "Tracking" (Yellow box)
         Name: "â€”"

Frame 2: Face detected in person box
         â†’ Run face recognition

Frame 3: Face matched to "Tovfikur Rahman"
         â†’ Update person_1
         Status: "Known" (Green box)
         Name: "Tovfikur Rahman"
         Confidence: 0.92
```

### Scenario 2: Face Temporarily Hidden
```
Frame 10: person_1 turns away, face not visible
          â†’ Keep tracking with last known data
          Status: "Known" (Green box)
          Name: "Tovfikur Rahman" (remembered)

Frame 15: Face visible again
          â†’ Re-detect face, update confidence
          Same ID: person_1 maintained
```

### Scenario 3: Unknown Person
```
Frame 1: New person â†’ person_2
         Status: "Tracking" (Yellow)

Frame 3: Face detected but not in database
         Status: "Unknown" (Red box)
         Name: "Unknown"
```

### Scenario 4: Person Leaves and Returns
```
Frame 20: person_1 exits frame
          â†’ frames_lost starts incrementing

Frame 40: Lost for 30 frames
          â†’ Track removed from memory

Frame 45: Same person re-enters
          â†’ New ID assigned: person_3
          â†’ Need face re-recognition
```

---

## âš™ï¸ Configuration Parameters

### Tracker Settings
```python
# backend/app.py

person_tracker = SimpleTracker(
    iou_threshold=0.3,       # Lower = stricter matching
    max_age=30,              # Higher = remember longer
    min_hits=1,              # Confirmations before tracking
    face_memory_time=3.0     # Face data retention (seconds)
)
```

### Face Recognition Settings
```python
# Tolerance for face matching
tolerance = 0.6  # Lower = stricter matching

# Confidence threshold for events
event_threshold = 0.7  # Only log high-confidence matches
```

---

## ğŸ”§ API Response Format

### `/api/recognize` Response
```json
{
  "success": true,
  "timestamp": "2025-11-10T12:30:45.123Z",
  "active_tracks": 2,
  "results": [
    {
      "track_id": 1,
      "person_bbox": [120.5, 50.2, 340.8, 480.1],
      "person_confidence": 0.95,
      "face_bbox": [180.3, 120.5, 280.7, 250.3],
      "name": "Tovfikur Rahman",
      "face_confidence": 0.92,
      "status": "Known",
      "frames_tracked": 45,
      "color": [0, 255, 0]
    },
    {
      "track_id": 2,
      "person_bbox": [450.0, 80.0, 620.0, 450.0],
      "person_confidence": 0.88,
      "face_bbox": null,
      "name": "â€”",
      "face_confidence": 0.0,
      "status": "Tracking",
      "frames_tracked": 5,
      "color": [255, 255, 0]
    }
  ]
}
```

---

## ğŸ¨ Frontend Display Logic

### Color Mapping
```javascript
// Determined by backend TrackedPerson.get_color()
const colors = {
  "Known": "rgb(0, 255, 0)",      // Green
  "Unknown": "rgb(255, 0, 0)",    // Red
  "Tracking": "rgb(255, 255, 0)"  // Yellow
};
```

### Label Format
```javascript
// Multi-line label with color-coded info
ID: person_{track_id}           // White, bold
Name: {name}                     // Green if Known, white otherwise
Conf: {confidence}%              // Orange (if available)
Status: {status}                 // Color-coded by status
```

---

## ğŸ“ˆ Performance Optimizations

1. **IoU-based Matching**: O(nÃ—m) complexity, efficient for typical scenarios
2. **Face Memory**: Prevents re-processing same face every frame
3. **Lazy Cleanup**: Removes old tracks only when necessary
4. **Single Face Processing**: Only processes primary face per person

---

## ğŸ”® Future Extensions

### Planned Features
- [ ] **Cross-camera Re-identification**: Track same person across multiple cameras
- [ ] **Movement Analytics**: Log entry/exit times, dwell time, trajectory
- [ ] **Historical Tracking**: Database logging with timestamps
- [ ] **Deep SORT Integration**: More robust tracking with appearance features
- [ ] **Multi-face Tracking**: Handle multiple faces per person
- [ ] **Confidence Smoothing**: Average confidence over time for stability

### Potential Enhancements
```python
# Example: Movement tracking
class TrackedPerson:
    trajectory: List[Tuple[float, float]]  # Center positions over time
    entry_time: datetime
    exit_time: Optional[datetime]
    total_dwell_time: float
```

---

## ğŸ§ª Testing Guide

### Manual Test Scenarios

1. **Single Person Tracking**
   - Start camera
   - Walk into frame
   - Verify: Yellow box appears with ID
   - Turn to show face
   - Verify: Box turns green, name appears
   - Turn away
   - Verify: Stays green with remembered name

2. **Multiple People**
   - Have 2-3 people in frame
   - Verify: Each gets unique ID
   - Verify: IDs don't swap when people move

3. **Face Hiding**
   - Be recognized (green box)
   - Cover face for 2 seconds
   - Verify: Stays green
   - Cover face for 5 seconds
   - Verify: May switch to yellow after face memory expires

4. **Exit and Re-entry**
   - Get recognized as person_1
   - Exit frame completely
   - Wait 5 seconds
   - Re-enter frame
   - Verify: May get new ID (e.g., person_2)
   - Verify: Re-recognition works

---

## ğŸ“ Debug Logging

### Backend Logs
```
[DEBUG] Detected 2 persons
[DEBUG] Tracking 2 persons
[DEBUG] Track 1: Found 1 faces
[DEBUG] Track 1: Recognized as Tovfikur Rahman (0.920)
[DEBUG] Returning 2 tracked persons to frontend
```

### Frontend Console
```javascript
[DEBUG] Recognition response: {
  active_tracks: 2,
  results: [
    { id: 1, name: "Tovfikur Rahman", status: "Known", frames: 45 },
    { id: 2, name: "â€”", status: "Tracking", frames: 5 }
  ]
}
```

---

## ğŸ¯ Summary

The new tracking system provides:
- âœ… Persistent person IDs across frames
- âœ… Automatic person-face linking
- âœ… Color-coded status visualization
- âœ… Intelligent face memory
- âœ… Robust tracking continuity
- âœ… Clean API with full tracking metadata

**Result**: You can now see "who is where" with continuous tracking, even when faces are temporarily hidden.
